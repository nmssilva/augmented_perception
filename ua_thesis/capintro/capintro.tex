\chapter{Introduction}
Technological studies in the fields of \gls{adas} and \gls{ad} have been growing in the past decades in the automobile industry and in the academic environment. 

It is important in \gls{ad} and \gls{adas} to implement machine learning methods so that the vehicles recognize what objects are in their surroundings. Therefore, labelled data is necessary to train machine learning algorithms. Data labelling is the solution to create datasets that will serve as input to learning algorithms.

This thesis is focused on the research of methods to register data into labels using a camera and \gls{lidar} sensors in ATLASCAR 2, so that the vehicle can later create a model of the objects it will detect and follow.

A tool for image labeling and tracking of objects will be developed. This tool will be used to gather image templates while tracking objects in the camera video. This dissertation will also improve some previous work, namely the calibration process in ATLASCAR 2.

\section{ATLAS Project}

ATLAS is a project developed by the Group of Automation and Robotics at the Department of Mechanical Engineering of the University of Aveiro, Portugal. The mission of the ATLAS project is to develop and enable the proliferation of advanced sensing and active systems designed for implementation in automobiles and affine platforms. Advanced active systems being improved, or newly developed, use data from vision, laser and other sensors. 

The ATLAS project has vast experience with autonomous navigation in controlled environments and is now evolving to deal with real road scenarios. To ensure that the developments are meeting the ATLAS project mission statement, a full sized prototype, the ATLASCAR 1, has been equipped with several state of the art sensors (\cite{LARlabs}). Currently, ATLASCAR 2 is the new full sized prototype being used for research equipped with \gls{lidar} sensors and a camera.

The ATLAS Project was created in 2003 and began with robots developed to participate at \gls{ad} competitions taking place at Portuguese National Robotics Festival. From this project, three small-sized platform robots were built (figure \ref{fig:atlasproto}). These robots were very successful having won prizes in some of the robotics competitions. 


\begin{figure}[htp]
	
	\centering
	\includegraphics[width=.3\textwidth]{capintro/imgs/atlas1}\hfill
	\includegraphics[width=.3\textwidth]{capintro/imgs/atlas2000}\hfill
	\includegraphics[width=.3\textwidth]{capintro/imgs/atlasmv}
	
	\caption{ATLAS project small-sized prototypes \cite{LARlabs}}
	\label{fig:atlasproto}
	
\end{figure}

As the project grew, it evolved into full-sized prototypes: the ATLASCARs. ATLASCAR1 (figure \ref{fig:atlascar1}) is the first full-sized platform and it is based on a Ford Escort Station Wagon. The ATLASCAR1 was equipped with several \gls{lidar} sensors and cameras. Data about its environment is gathered by the scanners which is then processed building perception into the car allowing it to actuate and move autonomously. 

\begin{figure}[htp]
	
	\centering
	\includegraphics[width=0.9\textwidth]{capintro/imgs/atlascar1}
	
	\caption{ATLASCAR1 based on the Ford Escort platform \cite{LARlabs}}
	\label{fig:atlascar1}
	
\end{figure}

The ATLASCAR1 brought successful results. In the end, the vehicle was able to move and execute maneuvers autonomously in small and controlled places. The ATLASCAR1 was then replaced by a more recent vehicle. The ATLASCAR2 (figure \ref{fig:atlascar2}) is the new full-sized platform of the ATLAS project and it is based on a Mitsubishi i-MiEV. This is the vehicle used for research in this dissertation. The ATLASCAR2 is equipped with various \gls{lidar} sensors and a camera. It is also a full electric vehicle which will be easier to modify, test and control. 

\begin{figure}[htp]
	
	\centering
	\includegraphics[width=0.9\textwidth]{capintro/imgs/atlas2.png}
	
	\caption{ATLASCAR 2 based on the Mitsubishi i-MiEV platform \cite{LARlabs}}
	\label{fig:atlascar2}
	
\end{figure}


\section{Motivation}

\gls{ad} and \gls{adas} often make use of machine learning. Deep learning algorithms utilize neural and convolutional networks for images and range-based sensor data. In the fields of machine learning, images are often used as input templates to create object models. In an image sequence it is possible to track an object and obtain samples of the target's location. This way an algorithm can automatically recognize targets.

While registering the position of the objects in an image sequence, it is important to tell what those objects are. Labelling is the act to classify objects in a certain category. As the annotation is done, when selecting an object, the user should enter a label that identifies the target making it easy for the learning algorithm to recognize to object afterwards.

The objective and importance of tagging samples of images with a label is to assign metadata in the form of a keyword to later allow an application to retrieve this information and easily construct a database. However, most labelling for images is currently done with non optimized manual procedures.

In the end of this dissertation, the ATLASCAR2 will have a labelling system that fuses images retrieved from the camera with the laser data, creating a semi automatic object tracking system that offers the possibility to retrieve various image template sequences and store metadata about them. This metadata contains, for instance, the label, object related identification markers and position of the object in the image and in the real world relatively to the ATLASCAR2.

\section{Objectives}
The objectives for this dissertation are, firstly, to improve the calibration of the camera, in particular regarding the detection of the ball by the camera in the existing multi-sensor calibration package developed using \gls{ros}. Secondly, the development of another \gls{ros} package used for semi-automatic detection and labelling of objects in the field of view.

The calibration package was already developed by \cite{VieiradaSilva2016}. The methods used to detect the ball in the camera image were basically filtering values from the \gls{hsv} color space. There are methods that can make this detection more robust that will be explained in this thesis. 

The detection, tracking and labelling system will combine the image data and the laser data from the sensors to create a semi-automatic tracking system that allows the user to associate an object category to the target and create datasets with metadata from the labelling.


\section{Document Structure}

This document is composed by seven chapters including the introduction. The second chapter describes the related work previously done on ATLASCAR 2 as well as a literature review detailing the most significant milestones on the history of autonomous driving and a research on image labelling datasets. 

In the third chapter, the experimental structure of this dissertation will be described depicting the hardware (ATLASCAR2 and sensors) and the software (\gls{ros}, \gls{lartk} and \gls{pcl}). 

In the fourth chapter, the implementation of the calibration node will be explained presenting its features, the base algorithm and how the calibration package was modified in order to improve the ball detection. 

In the fifth chapter, the detection, tracking and labelling node development will be explained, firstly by describing how the image tracking is done, then clarifying how to track objects using the \gls{lidar} sensors and finally using both the image and laser sensor data. This chapter also features the created datasets and some extra tools used to aid in the labelling. 

The sixth chapter presents the results of the ball detection and integration with the calibration package will be shown and the outcome of the labelling node will also be analyzed using some datasets produced by the same. 

The final chapter the conclusions of this thesis are presented and some future work related to the scope of this dissertation is proposed.


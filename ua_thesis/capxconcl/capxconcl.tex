
\chapter{Conclusions and Future Work}

In this chapter it will be wrapped up the work done during this dissertation regarding the creating of a \gls{ros} package, implementation of the ball detection node and the labelling node. Having this conclusions as a foundation, a few related future works will be proposed in the scope of the ATLASCAR2 project and the \gls{ad} and \gls{adas} paradigm.

\section{Conclusions}

The \gls{ad} and \gls{adas} fields are a research area prioritized by many car manufacturers. Building perception of the environment surrounding a vehicle is the solution to create anti collision systems, path planning, among other applications. Platforms are usually equipped with several data acquisition devices in which they resort to gather information of the environment. With a fully equipped vehicle the data can be manipulated and several applications can be built. Before, any use of the sensors data can be done, an extrinsic calibration is key to obtain the several devices relative positions. 

By using a calibration \gls{gui} the ATLASCAR2 is able to produce the extrinsic values of the sensors to a reference device. By moving a ball around in front of the sensors, a pointcloud of ball centers is created and by aligning the pointcloud the transformation matrices are calculated. One one hand, camera calibration uses image methods, but in the other hand, the \gls{lidar} sensors use range based methods. One has to calibrate the camera using other strategies since the data from the camera is different from the laser data. To improve the ball detection in the camera image the major improvement made was based on the background removal technique. By subtracting the background frame to the actual frame it is possible to obtain the objects that move in front of the camera. Erosion processes were made to filter noise in the background caused by lightning changes and, finally, a color filtering is done by selecting the color of the ball. In addiction to the previous work done on the calibration package, the ball detection was improved and the \gls{gui} was simplified. The old \gls{gui} featured sliders to choose the \gls{hsv} values of the ball whereas now those values can be obtain by simply clicking in the ball on the image.

With the sensors fully calibrated the ATLASCAR2 is ready to gather data and use that data to build applications. Labelling of objects is an important subject the \gls{ad} and \gls{adas} since it is linked with the recognition of objects. It is important for an autonomous vehicle to know what object is in front of them and act according to them. To build the labelling system, it was first implemented ways to detect and track objects using the image and sensor data. Tracking using the visual information was done with template matching where an object is selected by clicking on the target and the tracking is made my successively updating the patch used in the matching method. Since the camera is mounted in a vehicle and it is in constant movement, some methods such as optical flow were not appropriate and the template matching strategy was the one that gave out better results. The range based tracking was accomplished thanks to the \gls{mtt} library which implemented algorithms that used the pointcloud generated by the several sensors and applied data clustering to separate the found objects. The spacial coordinates of the found objects are outputted by the \gls{mtt} algorithm and the 3D tracking is realized. To obtain maximum accuracy with the tracking the sensor data nd the images are merged. The data fusion is optimal to create detection and tracking applications and the system may also become semi-automatic with the aid of both information from the \gls{lidar}s and the camera. While tracking objects, it is important to classify them and this is why it is assigned to each object a label. In the end, datasets are created with a fully annotated sequence denoting where objects are found and to what class they belong. 

\section{Future Work}

The possibilities of future work on ATLASCAR2 regarding \gls{ad} and \gls{adas} are endless. Some interesting and worth mentioning projects would be the development of a fully automatic detection and tracking system used for labelling in order to create more robust datasets as an extension to the work on this dissertation. 

The scope of this dissertation was based on objects such as cars, people and some miscellaneous objects on the streets. To expand this, a street sign detection system would be fundamental for the ATLASCAR2 to become fully autonomous. It is important for the vehicle to move in the street accordingly to the street rules.

The Machine Learning is a essential study field for the \gls{ad} and \gls{adas} projects. So, the image templates and datasets produced by this dissertation can serve as input for a learning algorithm that may implement a full detection, tracking and recognition system for the ATLASCAR2. It is important for autonomous vehicles to act according to what is facing in front of them.

The next step in detection and tracking would be implementing an automatic detection and tracking system and the development of a labelling system using augmented reality glasses.



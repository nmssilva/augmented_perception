
\chapter{Conclusions and Future Work}

This chapter concludes the work done during this dissertation regarding the creating of a \gls{ros} package, improvement of the ball detection node and the labelling node. Having this conclusions as a foundation, a few related future works will be proposed in the scope of the ATLASCAR2 project and the \gls{ad} and \gls{adas} paradigm.

\section{Conclusions}

\gls{ad} and \gls{adas} fields are a research area prioritized by many car manufacturers. Building perception of the environment surrounding a vehicle is the solution to create anti collision systems, path planning systems, among other applications. Platforms are usually equipped with several sensors to gather information from the environment. With a fully equipped vehicle the data can be manipulated and several applications can be built. Before, any use of the sensors data can be done, an extrinsic calibration is necessary to obtain the several devices relative positions. 

To improve the ball detection in the calibration process the major improvement made was based on the background removal technique. Erosion processes were made to filter noise and color filtering was done by selecting the color of the ball. In addiction to the previous work done on the calibration package, the ball detection was improved and the \gls{gui} was simplified. The old \gls{gui} featured sliders to choose the \gls{hsv} values of the ball whereas now those values can be obtain by simply clicking in the ball on the image.

With the sensors fully calibrated the ATLASCAR2 is ready to gather data. Labelling of objects is an important subject the \gls{ad} and \gls{adas} since it is linked with the recognition of objects. It is important for an autonomous vehicle to know what object is in front of them and act according to them. To build the labelling system, it was first implemented ways to detect and track objects using the image and sensor data. Tracking using the visual information was done with template matching where an object is selected by clicking on the target and the tracking is made by iteratively updating the patch used in the matching method. Since the camera is mounted in a vehicle in constant movement, some methods such as optical flow were not appropriate and the template matching strategy was the one that produced better results. The range based tracking was accomplished thanks to the \gls{mtt} library which implemented algorithms that used the pointcloud generated by the several sensors and applied data clustering to separate the found objects. The spacial coordinates of the found objects are outputted by the \gls{mtt} algorithm and the 3D tracking is realized. To obtain maximum accuracy with the tracking the sensor data and the images are merged. The data fusion is used to create detection and tracking applications and the system may also become semi-automatic with the aid of both information from the \gls{lidar}s and the camera. While tracking objects, it is important to classify them and this is why it is assigned to each object a label. In the end, datasets are created with a fully annotated sequence showing where objects are found and to what class they belong. 

\section{Future Work}

The possibilities of future work on ATLASCAR2 regarding \gls{ad} and \gls{adas} are many. Some interesting and worth mentioning projects would be the development of a more automatic detection and tracking system used for labelling in order to create more robust suggestions and datasets as an extension to the work on this dissertation. 

The Machine Learning is a essential study field for the \gls{ad} and \gls{adas} projects. So, the image templates and datasets produced by this dissertation can serve as input for a learning algorithm that may implement a full detection, tracking and recognition system for the ATLASCAR2.

The scope of this dissertation was based on objects such as cars, people and some miscellaneous objects on the streets. To expand this, a street sign detection system would be important for the ATLASCAR2 to become fully autonomous.

Using augmented reality glassed would also be an interesting project to develop a detection, tracking and labelling system.

